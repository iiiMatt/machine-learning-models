{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with np.load(path) as f:\n",
    "        x_train, y_train = f['x_train'], f['y_train']\n",
    "        x_test, y_test = f['x_test'], f['y_test']\n",
    "        return (x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading the MNIST dataset\n",
    "\"\"\"\n",
    "\n",
    "x_train,y_train,x_test,y_test = load_data('mnist.npz')\n",
    "x_train = x_train.reshape(60000,-1,1)/255\n",
    "y_train = list(y_train)\n",
    "for i,y in enumerate(y_train):\n",
    "    y_ =  np.zeros((10,1))\n",
    "    y_[y] = 1\n",
    "    y_train[i] = y_\n",
    "y_train = np.array(y_train)\n",
    "x_test = x_test.reshape(10000,-1,1)/255\n",
    "y_test = list(y_test)\n",
    "for i,y in enumerate(y_test):\n",
    "    y_ =  np.zeros((10,1))\n",
    "    y_[y] = 1\n",
    "    y_test[i] = y_\n",
    "y_test = np.array(y_test)\n",
    "train_data = list(zip(x_train, y_train))\n",
    "test_data = list(zip(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\" Simple python neural network implementation with the help of numpy \"\"\"\n",
    "    def __init__(self,sizes):\n",
    "        s = sizes\n",
    "        self.L = len(s)  # number of layers\n",
    "        self.shapes = list(zip(s[1:],s[:-1]))  # shapes of the weight matricies\n",
    "        self.weights = [np.random.randn(*s) for s in self.shapes]  # Initializing the weights\n",
    "        self.times = []\n",
    "        self.accuracies = []\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        \"\"\" Sigmoid activation function \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    \n",
    "    def sigmoid_p(self,x):\n",
    "        \"\"\" Sigmoid prime \"\"\"\n",
    "        g = self.sigmoid(x)\n",
    "        return g * (1 - g)\n",
    "    \n",
    "    \n",
    "    def predict(self,x):\n",
    "        \"\"\" Predicts the value of the given input \"\"\"\n",
    "        g = self.sigmoid\n",
    "        a = x\n",
    "        for w in self.weights:\n",
    "            a = g(w @ a)\n",
    "        return a\n",
    "    \n",
    "    \n",
    "    def accuracy(self,test_data):\n",
    "        \"\"\" Tests the accuracy of the model \"\"\"\n",
    "        good = 0\n",
    "        for i in test_data:\n",
    "            x = np.argmax(self.predict(i[0]))\n",
    "            y = np.argmax(i[1])\n",
    "            good += x == y\n",
    "        return good\n",
    "\n",
    "    \n",
    "    def train(self, train_data, learning_rate, batch_size, epochs, test_data):\n",
    "        \"\"\" Trains the model with stochastic gradient descent \"\"\"\n",
    "        all_time = time.time()\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_time = time.time()\n",
    "            random.shuffle(train_data)  # Shuffling the data so it can be randomly put into batches\n",
    "            m = len(train_data)\n",
    "            \n",
    "            # Initializig the batches\n",
    "            batches = [train_data[i * batch_size:(i + 1) * batch_size] for i in range(m // batch_size + 1)]\n",
    "            for batch in batches:\n",
    "                if batch:\n",
    "                    \n",
    "                    # Updating the weights based on the batch\n",
    "                    self.update_mini_batch(batch, learning_rate)\n",
    "            if test_data:\n",
    "                \n",
    "                # Calculating the run time of the epoch and testing the accuracy\n",
    "                epoch_time_ = round(time.time() - epoch_time, 2)\n",
    "                self.times.append(epoch_time_)\n",
    "                test_data_len = len(test_data)\n",
    "                acc = self.accuracy(test_data)\n",
    "                self.accuracies.append((acc / test_data_len)*100)\n",
    "                \n",
    "                # Logging the accuracy and the epoch time\n",
    "                print(f\"epoch {epoch}: {acc} / {test_data_len}, {epoch_time_}s\")\n",
    "        print(str(round(time.time() - all_time, 2)) + \"s\")\n",
    "#         return self.weights\n",
    "                \n",
    "    \n",
    "    def update_mini_batch(self, batch, learning_rate):\n",
    "        m = len(batch)\n",
    "        DELTAS = [np.zeros(w.shape) for w in self.weights]\n",
    "        for b in batch:\n",
    "            delta = self.backprop(b)\n",
    "            for i  in range(self.L - 1):\n",
    "                DELTAS[i] += delta[i]\n",
    "        for i in range(self.L - 1):\n",
    "            self.weights[i] -= (learning_rate / m) * DELTAS[i]\n",
    "    \n",
    "    def backprop(self, item):\n",
    "        a = item[0]\n",
    "        y = item[1]\n",
    "        a_ = [a]\n",
    "        z_ = []\n",
    "        for w in self.weights:\n",
    "            z = w @ a\n",
    "            z_.append(z)\n",
    "            a = self.sigmoid(z)\n",
    "            a_.append(a)\n",
    "        delta_ = [a - y]\n",
    "        for i in range(self.L - 2):\n",
    "            delta_.append(self.weights[self.L-2-i].T @ delta_[i] * self.sigmoid_p(z_[self.L-3-i]))\n",
    "        \n",
    "        delta = []\n",
    "        for i in range(self.L - 1):\n",
    "            delta.append(delta_[self.L-2-i] @ a_[i].T)\n",
    "        return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork([784,16,16,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_data, 0.5, 500, 3, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
