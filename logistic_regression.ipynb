{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.m = len(x)\n",
    "        self.n = len(x[0])\n",
    "        self.cost = 0\n",
    "        self.weights = np.random.randn(len(x[0]))\n",
    "        self.all_iterations = 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def gradient_descent(self, iterations, learning_rate, accuracy_at_cost, penalization = 0):\n",
    "        x = self.x\n",
    "        y = self.y\n",
    "        m = self.m\n",
    "        n = self.n\n",
    "        f = self.sigmoid\n",
    "        w = self.weights\n",
    "        d_w = np.ones((n))\n",
    "        for i in range(1, iterations+1):\n",
    "            h = f(np.sum(x*w,axis=1))\n",
    "            try:\n",
    "                cost = -(1 / m) * sum((y * np.log(h)) + ((1 - y) * np.log(1 - h))) + (penalization / m) * sum(weights)\n",
    "            except:\n",
    "                cost = 0\n",
    "#             if round(cost, accuracy_at_cost) == 0 or self.cost == cost:\n",
    "#                 print(i, round(cost,accuracy_at_cost))\n",
    "#                 break\n",
    "            self.cost = cost\n",
    "            if i % (iterations//10 or 1) == 0 or i == 1 or i == iterations:\n",
    "                print(i, cost)\n",
    "            for j in range(n):\n",
    "                d_w[j] = (1 / m) * sum(((h - y) * x[:,j])) + (penalization / m) * sum(w)\n",
    "            w = w - learning_rate * d_w\n",
    "            self.all_iterations += 1\n",
    "        self.weights = w\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.sigmoid(np.sum(x*self.weights,axis=1)) if x.ndim == 2 else self.sigmoid(sum(x*self.weights))\n",
    "    \n",
    "    def accuracy(self,x,y):\n",
    "        m = len(x)\n",
    "        pred = np.round(self.predict(x))\n",
    "        good = [pred[i] == y[i] for i in range(m)]\n",
    "        return sum(good) / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = make_blobs([1000,1000],cluster_std=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_descent(1000,0.03,4,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y)):\n",
    "    print(np.round(model.predict(x[i])),y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.accuracy(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.accuracy(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
